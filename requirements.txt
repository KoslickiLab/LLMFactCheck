# For GPU support (optional, requires CUDA)
# CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose

# Other dependencies
pandas==1.3.3
numpy==1.23.0
llama-cpp-python==0.1.78
huggingface-hub==0.0.12
